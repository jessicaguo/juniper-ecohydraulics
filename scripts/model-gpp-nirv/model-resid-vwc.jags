model{
    for(i in 1:N){
    
    # Normal likelihood of residuals
    resid[i] ~ dnorm(mu[i], tau)
    resid.rep[i] ~ dnorm(mu[i], tau)
    
    # Mean model
    mu[i] = B[1] + 
      B[2] * W10ant[i]
    
    # Antecedent variable is the sum across all timesteps
    W10ant[i] <- sum(W10Temp[i,])
    
    # Multiply weight by each timestep of covariate
    # Indexing tricks used to accomodate flexible time step size pA - pC
    
    for(k in 1:nlagB){
      W10Temp[i,k] <- mean(W10[(doy[i]-k*pB+1):(doy[i]-k*pB+pB)])*wB[k]
    }
    
    
    # Part of the calculation of the posterior predictive loss	
    Sqdiff[i] <- pow(resid.rep[i] - resid[i],2)
  }
  
  # Sum of the deltas for each covariate
  sumB <- sum(deltaB[])
  
  # Compute Bayesian R2 value
  var.pred <- pow(sd(mu[]),2)
  var.resid <- 1/tau
  R2_resid <- var.pred/(var.pred + var.resid)

  # Priors for weights using the delta trick
  # Daily variable weights

  for(k in 1:nlagB){
    wB[k] <- deltaB[k] / sumB
    deltaB[k] ~ dgamma(alphaB[k], 1)
  }
  
  # Normal priors for regression parameters
  for(j in 1:NParam) { # Number of parameters in linear models
    B[j] ~ dnorm(0, 0.001)
  }
  
  # Priors for variance terms
  tau ~ dgamma(0.1, 0.1)
  sig <- pow(tau, -0.5)
    
  # Posterior predictive loss is the posterior mean of Dsum
  Dsum <- sum(Sqdiff[])
  
}
